{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from Preparation import prepare_to_file, prepare_and_return\n",
    "from Scoring import score, initialize_result_file\n",
    "from Scenarios import drop_columns,remove_missing,fill_missing_mode,fill_missing_max,fill_missing_min,fill_missing_mean,fill_missing_regression,fill_missing_zero,standardize,normalize,remove_outliers_lof,encode_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_stats_1 = pd.read_csv('../Datasets/Prepared/lol_stats_1.csv')\n",
    "lol_stats_2 = pd.read_csv('../Datasets/Prepared/lol_stats_2.csv')\n",
    "lol_stats_3 = pd.read_csv('../Datasets/Prepared/lol_stats_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 3, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_stats_1['Tier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name         Akali\n",
       "Class     Assassin\n",
       "Role           MID\n",
       "Tier             1\n",
       "Score        65.49\n",
       "Trend         4.33\n",
       "Win %        48.41\n",
       "Role %       75.74\n",
       "Pick %        8.11\n",
       "Ban %        13.02\n",
       "KDA           2.37\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_stats_1.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Name', 'Class', 'Role','Tier']\n",
    "numeric = ['Score','Trend','Win %','Role %','Pick %', 'Ban %','KDA']\n",
    "to_be_encoded = ['Class', 'Role']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_preprocessing(df,num):\n",
    "    df_1 = df.copy()\n",
    "    df_1 = remove_missing(df_1)\n",
    "    y = df_1['Tier']\n",
    "    df_1= drop_columns(df_1,categorical)\n",
    "    df_1 = df_1.apply(pd.to_numeric)\n",
    "    X = df_1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Brak\",\"Brak przygotowania\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean(df, num):\n",
    "    df_2 = df.copy()\n",
    "    df_2 = fill_missing_mean(df_2,numeric)\n",
    "    y = df_2['Tier']\n",
    "    df_2 = drop_columns(df_2,categorical)\n",
    "    df_2 = df_2.apply(pd.to_numeric)\n",
    "    X = df_2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie średnią\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_min(df,num):\n",
    "    df_3 = df.copy()\n",
    "    df_3 = fill_missing_min(df_3,numeric)\n",
    "    y = df_3['Tier']\n",
    "    df_3 = df_3.drop(categorical,axis=1)\n",
    "    df_3 = df_3.apply(pd.to_numeric)\n",
    "    X = df_3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie minimum\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_max(df,num):\n",
    "    df_4 = df.copy()\n",
    "    df_4 = fill_missing_max(df_4,numeric)\n",
    "    y = df_4['Tier']\n",
    "    df_4 = df_4.drop(categorical,axis=1)\n",
    "    df_4 = df_4.apply(pd.to_numeric)\n",
    "    X = df_4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie maksimum\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_regression(df,num):\n",
    "    df_new = df.copy()\n",
    "    df_new = fill_missing_regression(df_new, numeric)\n",
    "    y = df_new['Tier']\n",
    "    df_new = df_new.drop(categorical,axis=1)\n",
    "    df_new = df_new.apply(pd.to_numeric)\n",
    "    X = df_new\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie regresją\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_scenario(df,num):\n",
    "    df_5 = df.copy()\n",
    "    df_5 = fill_missing_mean(df_5,numeric)\n",
    "    df_5 = standardize(df_5,numeric)\n",
    "    y = df_5['Tier']\n",
    "    df_5 = df_5.drop(categorical,axis=1)\n",
    "    df_5 = df_5.apply(pd.to_numeric)\n",
    "    X = df_5\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Standaryzacja\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scenario(df,num):\n",
    "    df_6 = df.copy()\n",
    "    df_6 = fill_missing_mean(df_6,numeric)\n",
    "    df_6 = normalize(df_6,numeric)\n",
    "    y = df_6['Tier']\n",
    "    df_6 = df_6.drop(categorical,axis=1)\n",
    "    df_6 = df_6.apply(pd.to_numeric)\n",
    "    X = df_6\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Skalowanie do (0-1)\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_remove_outliers(df,num):\n",
    "    df_7 = df.copy()\n",
    "    df_7 = fill_missing_mean(df_7,numeric)\n",
    "    df_7 = normalize(df_7,numeric)\n",
    "    df_7 = remove_outliers_lof(df_7,numeric)\n",
    "    y = df_7['Tier']\n",
    "    df_7 = df_7.drop(categorical,axis=1)\n",
    "    df_7 = df_7.apply(pd.to_numeric)\n",
    "    X = df_7\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Skalowanie (0-1) + usuw. odstających\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_scenario(df,num):\n",
    "    df_8 = df.copy()\n",
    "    df_8 = remove_missing(df_8)\n",
    "    df_8 = encode_categorical(df_8,to_be_encoded)\n",
    "    y = df_8['Tier']\n",
    "    df_8= drop_columns(df_8,['Name'])\n",
    "    df_8 = df_8.apply(pd.to_numeric)\n",
    "    X = df_8\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Kodowanie\",\"Kodowanie wartości kategorycznych\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_and_fill_missing(df,num):\n",
    "    df_9 = df.copy()\n",
    "    df_9 = fill_missing_mean(df_9,numeric)\n",
    "    df_9 = encode_categorical(df_9,to_be_encoded)\n",
    "    y = df_9['Tier']\n",
    "    df_9= drop_columns(df_9,['Name'])\n",
    "    df_9 = df_9.apply(pd.to_numeric)\n",
    "    X = df_9\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Kodowanie\",\"Kod. war. kategorycznych + wyp. brak. średnią\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scenario(df,num):\n",
    "    df_10 = df.copy()\n",
    "    df_10 = fill_missing_mean(df_10,numeric)\n",
    "    df_10 = remove_outliers_lof(df_10,numeric)\n",
    "    df_10 = normalize(df_10,numeric)\n",
    "    df_10= drop_columns(df_10,['Name'])\n",
    "    df_10 = encode_categorical(df_10,to_be_encoded)\n",
    "    y = df_10['Tier']\n",
    "    df_10 = df_10.apply(pd.to_numeric)\n",
    "    X = df_10\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Custom\",\"Custom preprocessing\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.9\n",
      "Random Forest Classifier: 0.8\n",
      "KNeighbors Classifier: 0.825\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.7346938775510204\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.6938775510204082\n",
      "KNeighbors Classifier: 0.7142857142857143\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.673469387755102\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.925\n",
      "Random Forest Classifier: 0.75\n",
      "KNeighbors Classifier: 0.825\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.7346938775510204\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7142857142857143\n",
      "KNeighbors Classifier: 0.673469387755102\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.673469387755102\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.9\n",
      "Random Forest Classifier: 0.625\n",
      "KNeighbors Classifier: 0.65\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7346938775510204\n",
      "KNeighbors Classifier: 0.6530612244897959\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.9183673469387755\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.6938775510204082\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.9183673469387755\n",
      "Random Forest Classifier: 0.7346938775510204\n",
      "KNeighbors Classifier: 0.6530612244897959\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    no_preprocessing(df_i,num)\n",
    "    fill_mean(df_i, num)\n",
    "    fill_min(df_i,num)\n",
    "    fill_max(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.6938775510204082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.7142857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "c:\\Users\\Darek\\Documents\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.673469387755102\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    fill_regression(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.7551020408163265\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.9387755102040817\n",
      "Random Forest Classifier: 0.7755102040816326\n",
      "KNeighbors Classifier: 0.6530612244897959\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Skalowanie do (0-1) z usuwaniem odstających\n",
      "Xgboost: 0.9111111111111111\n",
      "Random Forest Classifier: 0.6888888888888889\n",
      "KNeighbors Classifier: 0.6888888888888889\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.7551020408163265\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7551020408163265\n",
      "KNeighbors Classifier: 0.6938775510204082\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Skalowanie do (0-1) z usuwaniem odstających\n",
      "Xgboost: 0.8636363636363636\n",
      "Random Forest Classifier: 0.6590909090909091\n",
      "KNeighbors Classifier: 0.6818181818181818\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7346938775510204\n",
      "KNeighbors Classifier: 0.6938775510204082\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.9591836734693877\n",
      "Random Forest Classifier: 0.7346938775510204\n",
      "KNeighbors Classifier: 0.7551020408163265\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Skalowanie do (0-1) z usuwaniem odstających\n",
      "Xgboost: 0.8666666666666667\n",
      "Random Forest Classifier: 0.4888888888888889\n",
      "KNeighbors Classifier: 0.6444444444444445\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    standardize_scenario(df_i,num)\n",
    "    normalize_scenario(df_i,num)\n",
    "    normalize_and_remove_outliers(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.925\n",
      "KNeighbors Classifier: 0.9\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Kodowanie wartości kategorycznych + wypełnienie średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.8979591836734694\n",
      "KNeighbors Classifier: 0.7142857142857143\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.7954545454545454\n",
      "KNeighbors Classifier: 0.9545454545454546\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.875\n",
      "KNeighbors Classifier: 0.825\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Kodowanie wartości kategorycznych + wypełnienie średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.9183673469387755\n",
      "KNeighbors Classifier: 0.7346938775510204\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.8181818181818182\n",
      "KNeighbors Classifier: 0.9318181818181818\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.725\n",
      "KNeighbors Classifier: 0.675\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Kodowanie wartości kategorycznych + wypełnienie średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.8979591836734694\n",
      "KNeighbors Classifier: 0.6938775510204082\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.7906976744186046\n",
      "KNeighbors Classifier: 1.0\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    encode_categorical_scenario(df_i,num)\n",
    "    encode_categorical_and_fill_missing(df_i,num)\n",
    "    custom_scenario(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
