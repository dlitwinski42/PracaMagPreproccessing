{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from Preparation import prepare_to_file, prepare_and_return\n",
    "from Scoring import score, initialize_result_file\n",
    "from Scenarios import drop_columns,remove_missing,fill_missing_mode,fill_missing_max,fill_missing_min,fill_missing_mean,fill_missing_regression,fill_missing_zero,standardize,normalize,remove_outliers_lof,encode_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol_stats_1 = pd.read_csv('../Datasets/Prepared/lol_stats_1.csv')\n",
    "lol_stats_2 = pd.read_csv('../Datasets/Prepared/lol_stats_2.csv')\n",
    "lol_stats_3 = pd.read_csv('../Datasets/Prepared/lol_stats_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 3, 5, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_stats_1['Tier'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name         Akali\n",
       "Class     Assassin\n",
       "Role           MID\n",
       "Tier             1\n",
       "Win %          NaN\n",
       "Role %       75.74\n",
       "Pick %        8.11\n",
       "Ban %        13.02\n",
       "KDA           2.37\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol_stats_1.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Name', 'Class', 'Role','Tier']\n",
    "numeric = ['Win %','Role %','Pick %', 'Ban %','KDA']\n",
    "to_be_encoded = ['Class', 'Role']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_preprocessing(df,num):\n",
    "    df_1 = df.copy()\n",
    "    df_1 = remove_missing(df_1)\n",
    "    y = df_1['Tier']\n",
    "    df_1= drop_columns(df_1,categorical)\n",
    "    df_1 = df_1.apply(pd.to_numeric)\n",
    "    X = df_1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Brak\",\"Brak przygotowania\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_mean(df, num):\n",
    "    df_2 = df.copy()\n",
    "    df_2 = fill_missing_mean(df_2,numeric)\n",
    "    y = df_2['Tier']\n",
    "    df_2 = drop_columns(df_2,categorical)\n",
    "    df_2 = df_2.apply(pd.to_numeric)\n",
    "    X = df_2\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie średnią\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_min(df,num):\n",
    "    df_3 = df.copy()\n",
    "    df_3 = fill_missing_min(df_3,numeric)\n",
    "    y = df_3['Tier']\n",
    "    df_3 = df_3.drop(categorical,axis=1)\n",
    "    df_3 = df_3.apply(pd.to_numeric)\n",
    "    X = df_3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie minimum\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_max(df,num):\n",
    "    df_4 = df.copy()\n",
    "    df_4 = fill_missing_max(df_4,numeric)\n",
    "    y = df_4['Tier']\n",
    "    df_4 = df_4.drop(categorical,axis=1)\n",
    "    df_4 = df_4.apply(pd.to_numeric)\n",
    "    X = df_4\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie maksimum\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_regression(df,num):\n",
    "    df_new = df.copy()\n",
    "    df_new = fill_missing_regression(df_new, numeric)\n",
    "    y = df_new['Tier']\n",
    "    df_new = df_new.drop(categorical,axis=1)\n",
    "    df_new = df_new.apply(pd.to_numeric)\n",
    "    X = df_new\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Wypełnienie_brakujących\",\"Wypełnienie regresją\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_scenario(df,num):\n",
    "    df_5 = df.copy()\n",
    "    df_5 = fill_missing_mean(df_5,numeric)\n",
    "    df_5 = standardize(df_5,numeric)\n",
    "    y = df_5['Tier']\n",
    "    df_5 = df_5.drop(categorical,axis=1)\n",
    "    df_5 = df_5.apply(pd.to_numeric)\n",
    "    X = df_5\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Standaryzacja\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scenario(df,num):\n",
    "    df_6 = df.copy()\n",
    "    df_6 = fill_missing_mean(df_6,numeric)\n",
    "    df_6 = normalize(df_6,numeric)\n",
    "    y = df_6['Tier']\n",
    "    df_6 = df_6.drop(categorical,axis=1)\n",
    "    df_6 = df_6.apply(pd.to_numeric)\n",
    "    X = df_6\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Skalowanie do (0-1)\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_remove_outliers(df,num):\n",
    "    df_7 = df.copy()\n",
    "    df_7 = fill_missing_mean(df_7,numeric)\n",
    "    df_7 = normalize(df_7,numeric)\n",
    "    df_7 = remove_outliers_lof(df_7,numeric)\n",
    "    y = df_7['Tier']\n",
    "    df_7 = df_7.drop(categorical,axis=1)\n",
    "    df_7 = df_7.apply(pd.to_numeric)\n",
    "    X = df_7\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Standaryzacja\",\"Skalowanie (0-1) + usuw. odstających\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_scenario(df,num):\n",
    "    df_8 = df.copy()\n",
    "    df_8 = remove_missing(df_8)\n",
    "    df_8 = encode_categorical(df_8,to_be_encoded)\n",
    "    y = df_8['Tier']\n",
    "    df_8= drop_columns(df_8,['Name'])\n",
    "    df_8 = df_8.apply(pd.to_numeric)\n",
    "    X = df_8\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Kodowanie\",\"Kodowanie wartości kategorycznych\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_and_fill_missing(df,num):\n",
    "    df_9 = df.copy()\n",
    "    df_9 = fill_missing_mean(df_9,numeric)\n",
    "    df_9 = encode_categorical(df_9,to_be_encoded)\n",
    "    y = df_9['Tier']\n",
    "    df_9= drop_columns(df_9,['Name'])\n",
    "    df_9 = df_9.apply(pd.to_numeric)\n",
    "    X = df_9\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Kodowanie\",\"Kod. war. kategorycznych + wyp. brak. średnią\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scenario(df,num):\n",
    "    df_10 = df.copy()\n",
    "    df_10 = fill_missing_mean(df_10,numeric)\n",
    "    df_10 = remove_outliers_lof(df_10,numeric)\n",
    "    df_10 = normalize(df_10,numeric)\n",
    "    df_10= drop_columns(df_10,['Name'])\n",
    "    df_10 = encode_categorical(df_10,to_be_encoded)\n",
    "    y = df_10['Tier']\n",
    "    df_10 = df_10.apply(pd.to_numeric)\n",
    "    X = df_10\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    score(\"LoL_Stats\",num,\"Custom\",\"Custom preprocessing\",X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.425\n",
      "KNeighbors Classifier: 0.375\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.5714285714285714\n",
      "Random Forest Classifier: 0.4897959183673469\n",
      "KNeighbors Classifier: 0.5510204081632653\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.5714285714285714\n",
      "Random Forest Classifier: 0.46938775510204084\n",
      "KNeighbors Classifier: 0.5918367346938775\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.5714285714285714\n",
      "Random Forest Classifier: 0.5306122448979592\n",
      "KNeighbors Classifier: 0.5510204081632653\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.6\n",
      "Random Forest Classifier: 0.45\n",
      "KNeighbors Classifier: 0.475\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.673469387755102\n",
      "Random Forest Classifier: 0.46938775510204084\n",
      "KNeighbors Classifier: 0.5102040816326531\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.673469387755102\n",
      "Random Forest Classifier: 0.46938775510204084\n",
      "KNeighbors Classifier: 0.6326530612244898\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.5918367346938775\n",
      "Random Forest Classifier: 0.4897959183673469\n",
      "KNeighbors Classifier: 0.4897959183673469\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Brak przygotowania\n",
      "Xgboost: 0.55\n",
      "Random Forest Classifier: 0.5\n",
      "KNeighbors Classifier: 0.55\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie średnią\n",
      "Xgboost: 0.6326530612244898\n",
      "Random Forest Classifier: 0.5102040816326531\n",
      "KNeighbors Classifier: 0.5102040816326531\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie minimum\n",
      "Xgboost: 0.6122448979591837\n",
      "Random Forest Classifier: 0.5510204081632653\n",
      "KNeighbors Classifier: 0.5102040816326531\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie maksimum\n",
      "Xgboost: 0.6530612244897959\n",
      "Random Forest Classifier: 0.5306122448979592\n",
      "KNeighbors Classifier: 0.5510204081632653\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    no_preprocessing(df_i,num)\n",
    "    fill_mean(df_i, num)\n",
    "    fill_min(df_i,num)\n",
    "    fill_max(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.5102040816326531\n",
      "KNeighbors Classifier: 0.5714285714285714\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.673469387755102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.5102040816326531\n",
      "KNeighbors Classifier: 0.5102040816326531\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Wypełnienie regresją\n",
      "Xgboost: 0.6122448979591837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n",
      "e:\\Magisterka\\PracaMagPreproccessing\\Titanic\\Scenarios.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].fillna(df[col].mean())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: 0.5306122448979592\n",
      "KNeighbors Classifier: 0.5306122448979592\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    fill_regression(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.5714285714285714\n",
      "Random Forest Classifier: 0.4897959183673469\n",
      "KNeighbors Classifier: 0.5714285714285714\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.5714285714285714\n",
      "Random Forest Classifier: 0.4897959183673469\n",
      "KNeighbors Classifier: 0.5510204081632653\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Skalowanie (0-1) + usuw. odstających\n",
      "Xgboost: 0.5777777777777777\n",
      "Random Forest Classifier: 0.37777777777777777\n",
      "KNeighbors Classifier: 0.5333333333333333\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.673469387755102\n",
      "Random Forest Classifier: 0.46938775510204084\n",
      "KNeighbors Classifier: 0.6122448979591837\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.673469387755102\n",
      "Random Forest Classifier: 0.46938775510204084\n",
      "KNeighbors Classifier: 0.5714285714285714\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Skalowanie (0-1) + usuw. odstających\n",
      "Xgboost: 0.6\n",
      "Random Forest Classifier: 0.4666666666666667\n",
      "KNeighbors Classifier: 0.4444444444444444\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Standaryzacja\n",
      "Xgboost: 0.6326530612244898\n",
      "Random Forest Classifier: 0.5102040816326531\n",
      "KNeighbors Classifier: 0.5918367346938775\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Skalowanie do (0-1)\n",
      "Xgboost: 0.6326530612244898\n",
      "Random Forest Classifier: 0.5102040816326531\n",
      "KNeighbors Classifier: 0.5510204081632653\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Skalowanie (0-1) + usuw. odstających\n",
      "Xgboost: 0.5555555555555556\n",
      "Random Forest Classifier: 0.3333333333333333\n",
      "KNeighbors Classifier: 0.37777777777777777\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    standardize_scenario(df_i,num)\n",
    "    normalize_scenario(df_i,num)\n",
    "    normalize_and_remove_outliers(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= LoL_Stats_1 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.825\n",
      "KNeighbors Classifier: 0.45\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Kod. war. kategorycznych + wyp. brak. średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.7142857142857143\n",
      "KNeighbors Classifier: 0.5510204081632653\n",
      "========= LoL_Stats_1 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.6739130434782609\n",
      "KNeighbors Classifier: 0.9130434782608695\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.775\n",
      "KNeighbors Classifier: 0.5\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Kod. war. kategorycznych + wyp. brak. średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.6938775510204082\n",
      "KNeighbors Classifier: 0.5918367346938775\n",
      "========= LoL_Stats_2 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.8\n",
      "KNeighbors Classifier: 0.9555555555555556\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Kodowanie wartości kategorycznych\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.825\n",
      "KNeighbors Classifier: 0.525\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Kod. war. kategorycznych + wyp. brak. średnią\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.7142857142857143\n",
      "KNeighbors Classifier: 0.5714285714285714\n",
      "========= LoL_Stats_3 =========\n",
      "Scenario: Custom preprocessing\n",
      "Xgboost: 1.0\n",
      "Random Forest Classifier: 0.6\n",
      "KNeighbors Classifier: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "for df_i in [lol_stats_1,lol_stats_2,lol_stats_3]:\n",
    "    encode_categorical_scenario(df_i,num)\n",
    "    encode_categorical_and_fill_missing(df_i,num)\n",
    "    custom_scenario(df_i,num)\n",
    "    num = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
